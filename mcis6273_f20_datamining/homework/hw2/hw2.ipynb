{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCIS6273 Data Mining (Prof. Maull) / Fall 2020 / HW2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Name: Manideepak Neeli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section: 029"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAU ID : 999901000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBJECTIVES\n",
    "<h4>1.Perform unsupervised learning with nearest-neighbors classification and regression</h4>\n",
    "<h4>2.Perform Bayesian text classification</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT TASKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (50%) Perform unsupervised learning with nearest-neighbors classification and regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last homework we work with the diamonds dataset and learned a lot about how to understand and visualize some of the features of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of the exercise, we're going to choose 5 labels for the diamonds all based on price. Instead of arbitrary cuts on those labels, we're going to use the 2015 US Federal income tax brackets as our guide.\n",
    "\n",
    "If you look at the brackets, there are distinct cutoffs which could serve as bins for our class labels. We don't care necessarily what the labels are called, so we will just use letters 'A', 'B', 'C' and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the modules\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  price     x     y     z\n",
       "0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "3   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database = pd.read_csv('https://git.io/JUGqS')\n",
    "database.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnc10(d):\n",
    "    return d * 0.10;\n",
    "def fnc15(d):\n",
    "    return d * 0.15;\n",
    "def fnc25(d):\n",
    "    return d * 0.25;\n",
    "def fnc28(d):\n",
    "    return d * 0.28;\n",
    "def fnc33(d):\n",
    "    return d * 0.33;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For each bracket compute a value $\\varphi$ which is 10% of half the difference between the\n",
    "   top and bottom of the bracket.\n",
    "   For example, $$\\varphi_c = \\frac{b_{max} - b_{min}}{2} \\times 0.10$$.\n",
    "\n",
    "\n",
    "   So if the top of a bracket $b_{max} = 5000$ and the bottom of the bracket $b_{min}=2500$, then\n",
    "   $\\varphi = 125$.  This number will represent the cutoff of the class, so that the range\n",
    "   for the class extends from the previous class to the current one just calculated.  The classes\n",
    "   will ultimately look like this $C_1 = [0, \\varphi_{c_1}], C_2 = (\\varphi_{c_1}, \\varphi_{c_2}], \\ldots, C_n =(\\varphi_{c_{n-1}}, \\varphi_{c_n}]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each bracket compute a value  ùúë "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countBracketRates(rate,min,max):\n",
    "    return (((max-min)/2)*(rate/100));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#From the above example\n",
    "countBracketRates(10,2500,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461.25"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10%\n",
    "countBracketRates(10,0,9225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2116.7999999999997"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 15%\n",
    "countBracketRates(15,9226,37450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6662.375"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 25%\n",
    "countBracketRates(25,37451,90750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36662.835"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 33%\n",
    "countBracketRates(33,189301, 411500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From diamond database\n",
    "### For each diamonds bracket compute a value  ùúë "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10% price Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.48500000000001"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countBracketRates(10,database.price.apply(fnc10).min(),database.price.apply(fnc10).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15% price Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208.09124999999997"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countBracketRates(15,database.price.apply(fnc15).min(),database.price.apply(fnc15).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25% price Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "578.03125"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countBracketRates(25,database.price.apply(fnc25).min(),database.price.apply(fnc25).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 33% price Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1007.1616500000001"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countBracketRates(33,database.price.apply(fnc33).min(),database.price.apply(fnc33).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Now label the original data from your diamonds data with the labels 'A' ... 'E' where 'A' is the first class, 'B', the second and so on. You will need to create a function that checks the class ranges for the price and applies that function accordingly to produce a new feature class. You can do this very simply with the apply function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnclabeler(d):\n",
    "    if (d >= 0.00 and d <= 3532.9):\n",
    "        return 'A'\n",
    "    elif (3533.0 >= 1.10 and d <= 7245.9):\n",
    "        return 'B'\n",
    "    elif (d >= 7246.0 and d <= 11000.9):\n",
    "        return 'C';\n",
    "    elif (d >= 11000.9 and d <= 14000.9):\n",
    "        return 'D';\n",
    "    elif (d >= 14001.0 and d <= 18823.0):\n",
    "        return 'E';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "database.price.apply(fnclabeler)\n",
    "database['size_label'] = database.price.apply(fnclabeler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = database.query('size_label == \"A\"')['size_label']\n",
    "B = database.query('size_label == \"B\"')['size_label']\n",
    "C = database.query('size_label == \"C\"')['size_label']\n",
    "D = database.query('size_label == \"D\"')['size_label']\n",
    "E = database.query('size_label == \"E\"')['size_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_a = pd.DataFrame({ 'A_Label': database.query('size_label == \"A\"')['size_label']})\n",
    "database_b = pd.DataFrame({ 'B_Label': database.query('size_label == \"B\"')['size_label']})\n",
    "database_c = pd.DataFrame({ 'C_Label': database.query('size_label == \"C\"')['size_label']})\n",
    "database_d = pd.DataFrame({ 'D_Label': database.query('size_label == \"D\"')['size_label']})\n",
    "database_e = pd.DataFrame({ 'E_Label': database.query('size_label == \"E\"')['size_label']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_Label</th>\n",
       "      <th>B_Label</th>\n",
       "      <th>C_Label</th>\n",
       "      <th>D_Label</th>\n",
       "      <th>E_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  A_Label B_Label C_Label D_Label E_Label\n",
       "0       A     NaN     NaN     NaN     NaN\n",
       "1       A     NaN     NaN     NaN     NaN\n",
       "2       A     NaN     NaN     NaN     NaN\n",
       "3       A     NaN     NaN     NaN     NaN\n",
       "4       A     NaN     NaN     NaN     NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#appending to datafream\n",
    "labels_data=database_a.append(database_b).append(database_c).append(database_c).append(database_d).append(database_e)\n",
    "labels_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Store the labeled data (the new DataFrame with the class) into a file for all rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the file labeled_data.csv\n",
    "labels_data.to_csv('labeled_data.csv ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that we have the dataset, let's create a training and test set and beging model building. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>size_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  price     x     y     z  \\\n",
       "0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43   \n",
       "1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31   \n",
       "2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31   \n",
       "3   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63   \n",
       "4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75   \n",
       "\n",
       "   size_label  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "#creating labelEncoder\n",
    "label_encoder= preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'species'. \n",
    "database['size_label']= label_encoder.fit_transform(database['size_label'])\n",
    "database.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a 25% validation set and use the remaining data to do a 30%/70% test/train split.  We have\n",
    "###   enough instances to create a dataset that should yield good accuracy.  The [`sklearn.model_selection.train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) is a great place to start\n",
    "###   and will save you a great deal of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37758, 7) (20766, 7) (16992, 7) (37758,) (20766,) (16992,)\n"
     ]
    }
   ],
   "source": [
    "#import the train and test splits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = database.drop(['cut', 'color', 'clarity'], axis=1).iloc[:,:7]\n",
    "y = database.size_label\n",
    "\n",
    "# validate and train and test data splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_train, y_train, test_size=0.45)\n",
    "print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Store the data into 3 files `test.csv`, `train.csv` and `validate.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data \n",
    "training = X_train\n",
    "training[\"y_train\"] = y_train\n",
    "training.head()\n",
    "# saving the dataframe \n",
    "training.to_csv('train.csv')\n",
    "\n",
    "#Test data\n",
    "testing = X_test\n",
    "testing[\"y_test\"] = y_test\n",
    "testing.head()\n",
    "# saving the dataframe \n",
    "testing.to_csv('test.csv')\n",
    "\n",
    "validating = X_val\n",
    "validating[\"y_val\"] = y_val\n",
    "# saving the dataframe \n",
    "validating.to_csv('validate.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier diamonds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Write the code in your notebook to build the classifier using the KNeighborsClassifier. Here are a few tips:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.make sure you split the class labels correctly (i.e. do not include them in the feature set expected in the  ùëã  parameter of the fit() method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model using the training sets\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Use the score method to test your model's accuracy. Your notebook must include an individual assessment of the score, which is the mean accuracy of the predict method over the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9999411487758946\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_data Accuracy: 1.00\n",
      "Test_data Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "#Metrics\n",
    "from sklearn import metrics\n",
    "# Accuracy Score\n",
    "accuracy_train = metrics.accuracy_score(y_train, knn.predict(X_train))\n",
    "accuracy_test = metrics.accuracy_score(y_test, knn.predict(X_test))\n",
    "accuracy_validate = metrics.accuracy_score(y_val, knn.predict(X_val))\n",
    "\n",
    "print ('Train_data Accuracy: %.2f' %accuracy_train)\n",
    "print ('Test_data Accuracy: %.2f' %accuracy_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Please comment on the accuracy of your model. Would you trust it in the wild? Why or Why not? If the accuracy is not what you would think is worthy, please go back and make updates to the  ùëò  parameter which you have control over in the previous step. When you have found a  ùëò  that is satisfactory, go to the next step (NOTE: this step may not be necessary, if for example, your classifier achieves > 0.80 accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors Score = 1 is 0.9999411487758946\n",
      "n_neighbors Score = 2 is 0.9999411487758946\n",
      "n_neighbors Score = 3 is 0.9999411487758946\n",
      "n_neighbors Score = 4 is 1.0\n",
      "n_neighbors Score = 5 is 1.0\n",
      "n_neighbors Score = 6 is 1.0\n",
      "n_neighbors Score = 7 is 1.0\n",
      "n_neighbors Score = 8 is 1.0\n",
      "n_neighbors Score = 9 is 1.0\n"
     ]
    }
   ],
   "source": [
    "for p in range(1, 10):\n",
    "    knn_mod = KNeighborsClassifier(n_neighbors=p);\n",
    "    knn_mod.fit(X_train, y_train);\n",
    "    \n",
    "    #Predict the test dta\n",
    "    y_pred = knn.predict(X_test)\n",
    "    #Score method\n",
    "    score_val = knn_mod.score(X_test, y_pred)\n",
    "    print(\"n_neighbors Score = \" + str(p) + \" is \" + str(score_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬ß Evaluating and reflecting on your model is an important and relevant step to take when building them. \n",
    "## Answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Now that you have a model and may be fairly happy with it, please score the data on the holdout set. Make sure you have a cell in your notebook that shows the accuracy of the model on the holdout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this model having the score the data on holdout set means validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Do you think the your model is ready for prime time? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "From this KNeighborsClassifier is not ready for prime time accurately. Becouse of finding neghours or nearest time to findout \n",
    "out the predectinon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. You will adapt your code above to produce the regressor (it will be very easy, instead of the classlabel as the input to the $y$ parameter of `fit`, use the price, of course making sure you drop it and the label from your $X$ input parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Testing is 0.9999411487758946\n"
     ]
    }
   ],
   "source": [
    "KNeighbors = KNeighborsClassifier(n_neighbors=4);\n",
    "KNeighbors.fit(X_train, y_train);\n",
    "print(\"Accuracy for Testing is \"+str(KNeighbors.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To complete this study the [`sklearn.neighbors.KNeighborsRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor).\n",
    "### Use the same splits as the classifier above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At K = 11, Max Accuracy = 97.22761823838766\n",
      "Validation score for n_neighbors = 1 is 0.9225802298151393\n",
      "Validation score for n_neighbors = 2 is 0.9367810267293107\n",
      "Validation score for n_neighbors = 3 is 0.9403095835877396\n",
      "Validation score for n_neighbors = 4 is 0.9516710452081539\n",
      "Validation score for n_neighbors = 5 is 0.9513243626645799\n",
      "Validation score for n_neighbors = 6 is 0.9583822620441835\n",
      "Validation score for n_neighbors = 7 is 0.9630242472002756\n",
      "Validation score for n_neighbors = 8 is 0.9638987564523509\n",
      "Validation score for n_neighbors = 9 is 0.9633942242433977\n"
     ]
    }
   ],
   "source": [
    "database = pd.read_csv('https://git.io/JUGqS')\n",
    "\n",
    "database['cut'] = database['cut'].map({'Fair' : 1, 'Good' : 2, 'Very Good' : 3, 'Premium' : 4, 'Ideal' : 5})\n",
    "database['clarity'] = database['clarity'].map({ 'I1' : 1, 'SI2' : 2, 'SI1' : 3, 'VS2' : 4, 'VS1' : 5, 'VVS2' : 6, 'VVS1' : 7 , 'IF' : 8})\n",
    "database['color'] = database['color'].map({'D':7, 'E':6, 'F':5, 'G':4, 'H':3, 'I':2, 'J':1})\n",
    "\n",
    "import sklearn\n",
    "database = sklearn.utils.shuffle(database, random_state = 62)\n",
    "X = database.drop(['price'], axis = 1).values\n",
    "X = preprocessing.scale(X)\n",
    "y = database['price'].values\n",
    "y = preprocessing.scale(y)\n",
    "\n",
    "testing_size = 250\n",
    "X_train = X[: -testing_size]\n",
    "y_train = y[: -testing_size]\n",
    "X_test = X[-testing_size :]\n",
    "y_test =  y[-testing_size :]\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "score = []\n",
    " # running for different K values to know which yields the max accuracy. \n",
    "for k in range(1,20):\n",
    "    clf = KNeighborsRegressor(n_neighbors = k,  weights = 'distance', p=1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score.append(clf.score(X_test, y_test ))\n",
    "\n",
    "k_max = score.index(max(score))+1\n",
    "print( \"At K = {}, Max Accuracy = {}\".format(k_max, max(score)*100))\n",
    "\n",
    "\n",
    "knn_models = {}\n",
    "for i in range(1, 10):\n",
    "    knn_models[str(i)] = KNeighborsRegressor(n_neighbors=i);\n",
    "    knn_models[str(i)].fit(X_train, y_train);\n",
    "    score = knn_models[str(i)].score(X_test, y_test)\n",
    "    print(\"Validation score for n_neighbors = \" + str(i) + \" is \" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The predict method works similarly as before except this time it returns an $R^2$ value\n",
    "   of the prediction recall the closer $R^2$ is to 1.0, the better the fit.  Make\n",
    "   sure you do the prediction on the test data.  Play with the model a bit if necessary\n",
    "   to determine the impact of changes on the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** KNeighbours Regression ******\n",
      "Score : 0.9513\n",
      "[0.96466661 0.96769321 0.96889164 0.96876871 0.96543016]\n",
      "\n",
      "R2     : 0.95 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.7s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "knghrs = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "#fit\n",
    "knghrs.fit(X_train , y_train)\n",
    "\n",
    "#Accuracy\n",
    "accuracies = cross_val_score(estimator = knghrs, X = X_train, y = y_train, cv = 5,verbose = 1)\n",
    "y_pred = knghrs.predict(X_test)\n",
    "\n",
    "print('')\n",
    "print('***** KNeighbours Regression ******')\n",
    "print('Score : %.4f' % knghrs.score(X_test, y_test))\n",
    "print(accuracies)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print('')\n",
    "\n",
    "print('R2     : %0.2f ' % r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take the validation set and again determine the score.  Do you feel the model is ready for prime time?  Please be specific on why you feel that way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validatin score is 0.9999589534051444\n"
     ]
    }
   ],
   "source": [
    "k_ne_reg = KNeighborsRegressor(n_neighbors=5)\n",
    "#fit\n",
    "k_ne_reg.fit(X_val , y_val)\n",
    "print(\"The validatin score is \"+str(k_ne_reg.score(X_val,y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Using your model, please take the sample file [hw2_price_test_sample.csv](./hw2_price_test_sample.csv)\n",
    "   from the course repo and produce prices for each\n",
    "   input instance.  The output will be a file with the price as a feature (output column in your\n",
    "   file).  Make sure you name the file `price_predictions.csv` so I can look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
