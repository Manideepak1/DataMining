{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCIS6273 Data Mining (Prof. Maull) / Fall 2020 / HW3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Name: Manideepak Neeli\n",
    "### SAU ID    : 999901000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OBJECTIVES\n",
    "* Perform Bayesian text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASSIGNMENT TASKS\n",
    "### (100%) Perform Bayesian text classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to work with the documents we want to load, you will want to study \n",
    "\n",
    "* [`from sklearn.feature_extraction.text import TfidfVectorizer`]()\n",
    "* [`from sklearn.naive_bayes import MultinomialNB`]()\n",
    "\n",
    "Our test data will be given by the following dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_map = {\n",
    "    'a': # Plato\n",
    "        [\n",
    "        'data/plato/test/pg1726.txt', # Title: Cratylus\n",
    "        'data/plato/test/pg1616.txt', # Title: Ion\n",
    "        'data/plato/test/pg1735.txt', # Title: Theaetetus \n",
    "        'data/plato/test/pg1635.txt'  # Title: Sophist\n",
    "        ],\n",
    "    'b': \n",
    "        [ # Hume\n",
    "        'data/hume/test/pg59792-0.txt', # Title: Hume's Political Discourses\n",
    "        'data/hume/test/pg62856-0.txt', # Title: A Treatise of Human Nature Being an Attempt to Introduce the Experimental Method into Moral Subjects\n",
    "        'data/hume/test/pg9662.txt',    # Title: An Enquiry Concerning Human Understanding\n",
    "        ],\n",
    "    'c':\n",
    "        [ # Aristotle\n",
    "        'data/aristotle/test/pg59058.txt', # Title: Aristotle's History of Animals In Ten Books\n",
    "        'data/aristotle/test/pg2412.txt',  # Title: The Categories\n",
    "        'data/aristotle/test/pg6762.txt',  # Title: Politics A Treatise on Government\n",
    "        'data/aristotle/test/pg1974.txt',  # Title: Poetics\n",
    "        ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_map = {\n",
    "    'a': \n",
    "        [ # Plato\n",
    "        'data/plato/train/pg1750.txt', # Laws\n",
    "        'data/plato/train/pg1497.txt', # The Republic\n",
    "        'data/plato/train/pg1600.txt', # Symposium\n",
    "        ],\n",
    "    'b':\n",
    "        [ # Hume\n",
    "        'data/hume/train/pg10574.txt', # The History of England, Volume I\n",
    "        'data/hume/train/pg4705.txt',  # A Treatise of Human Nature\n",
    "        'data/hume/train/pg36120.txt', # Essays\n",
    "        ],\n",
    "    'c':\n",
    "        [ # Aristotle\n",
    "        'data/aristotle/train/pg8438.txt', # Ethics\n",
    "        'data/aristotle/train/pg26095.txt',# The Athenian Constitution\n",
    "        'data/aristotle/train/pg6763.txt'  # The Poetics\n",
    "        ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_train = []\n",
    "y_train = []\n",
    "\n",
    "for k in training_map.keys():\n",
    "    files_train.extend(training_map[k])\n",
    "    y_train.extend(k * len(training_map[k]))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/plato/train/pg1750.txt',\n",
       " 'data/plato/train/pg1497.txt',\n",
       " 'data/plato/train/pg1600.txt',\n",
       " 'data/hume/train/pg10574.txt',\n",
       " 'data/hume/train/pg4705.txt',\n",
       " 'data/hume/train/pg36120.txt',\n",
       " 'data/aristotle/train/pg8438.txt',\n",
       " 'data/aristotle/train/pg26095.txt',\n",
       " 'data/aristotle/train/pg6763.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'a', 'a', 'b', 'b', 'b', 'c', 'c', 'c']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the dictionary map in the variable\n",
    "          `training_map`. Your function will take the files (in the order they appear in\n",
    "          `training_map`) and pass the  data into the [`TfidfVectorizer`]() vectorizer.  You\n",
    "          will need to set the parameter to the constructor to `input='file'` and the\n",
    "          `stop_words` to `'english'` (e.g. initialize the vectorizer to `TfidfVectorizer(input='file', stop_words='english')`.\n",
    "\n",
    "* **You will just need to show the new function and the initialization of the vectorizer in this step.**  This will be one or two cells at most.\n",
    "* You will use `fit_transform()` with the parameter being a list of the training files objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVectorizerVectors(files_train,vectorizer):\n",
    "    # call vectorizer.fit_transform on the list of FILE OBJECTS\n",
    "    \n",
    "    vectorizer_vectors = vectorizer.fit_transform([open(file, 'r', encoding='utf-8') for file in files_train if file.endswith(\"txt\")]).astype(int)\n",
    "    return vectorizer_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9x24856 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 61769 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(input='file', stop_words='english')\n",
    "tfidf_vectorizer_vectors = getVectorizerVectors(files_train,vectorizer)\n",
    "tfidf_vectorizer_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tfidf_vectorizer_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer_vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 24856)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer_vectors.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART II\n",
    "\n",
    "Now that you have a vectorizer which effectively builds the data structure to hold the\n",
    "TF-IDF of all the words which appear for each document, you can move to the training\n",
    "phase for the Bayesian classifier.  Look in the sample notebook for guidance. You will take as\n",
    "input the vectorizer output (the documents vectorized by TF-IDF) and the corresponding\n",
    "classes (in the order they appear in the original dictionary map) and pass that into the [`MultinomialNB.fit()`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.fit) method.\n",
    "\n",
    "* **Show the initialization of your `MultinomialNB()` classifier and the application of the `fit()` method.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# initialize MultinomialNB (one line) (e.g. clf = ???)\n",
    "clf = MultinomialNB()\n",
    "# e.g. clf.fit( with_the_approproate_parameters )\n",
    "clf.fit(tfidf_vectorizer_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 24856)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.33333333333333"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(tfidf_vectorizer_vectors,y_train)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART III\n",
    "\n",
    "Once you have the classifier, you will need to convert a test file using\n",
    "the vectorizer from part I.  Then you will execute the `predict()` \n",
    "method of your classifier.\n",
    "\n",
    "Assume `vectorizer` is your TF-IDF vectorizer from above and the `clf` your\n",
    "classifier from part II above, your code could be modeled after this:\n",
    "\n",
    "```python\n",
    "x_test = vectorizer.transform([open(\"data/aristotle/test/pg2412.txt\")])\n",
    "\n",
    "# should be class C!\n",
    "clf.predict(x_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your notebook do the following:\n",
    "\n",
    "1. **Write a function to take as input a vectorized document and trained classifier and return\n",
    "the predicted label for the document.**  See the sample notebook for guidance.\n",
    "\n",
    "1. **Test on the files in the `data/philosopher_name/test` folders and show the output of your test.**\n",
    "You can wrap your function from the previous step in a loop\n",
    "to run through all data in the folder.  This will be short enough to be coded in a single Jupyter cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_test = [\n",
    "   #(\"data/aristotle/test/pg2412.txt\", 'c'), # the class should match the file (e.g. Hume is 'b') \n",
    "   # add all the remaining files\n",
    "    ('data/plato/test/pg1726.txt','a') ,\n",
    "    ('data/plato/test/pg1616.txt','a'),\n",
    "    ('data/plato/test/pg1735.txt','a'),\n",
    "    ('data/plato/test/pg1635.txt','a'),\n",
    "    ('data/hume/test/pg59792-0.txt','b'),\n",
    "    ('data/hume/test/pg62856-0.txt','b'),\n",
    "    ('data/hume/test/pg9662.txt','b'),\n",
    "    ('data/aristotle/test/pg59058.txt','c'),\n",
    "    ('data/aristotle/test/pg2412.txt','c'),\n",
    "    ('data/aristotle/test/pg6762.txt','c'),\n",
    "    ('data/aristotle/test/pg1974.txt','c')\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictValue(x_test,clf):\n",
    "    return clf.predict(x_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24856)\n",
      "a : a\n",
      "data/plato/test/pg1726.txt: True\n",
      "(1, 24856)\n",
      "a : a\n",
      "data/plato/test/pg1616.txt: True\n",
      "(1, 24856)\n",
      "a : a\n",
      "data/plato/test/pg1735.txt: True\n",
      "(1, 24856)\n",
      "a : a\n",
      "data/plato/test/pg1635.txt: True\n",
      "(1, 24856)\n",
      "b : a\n",
      "data/hume/test/pg59792-0.txt: False\n",
      "(1, 24856)\n",
      "b : a\n",
      "data/hume/test/pg62856-0.txt: False\n",
      "(1, 24856)\n",
      "b : a\n",
      "data/hume/test/pg9662.txt: False\n",
      "(1, 24856)\n",
      "c : a\n",
      "data/aristotle/test/pg59058.txt: False\n",
      "(1, 24856)\n",
      "c : a\n",
      "data/aristotle/test/pg2412.txt: False\n",
      "(1, 24856)\n",
      "c : a\n",
      "data/aristotle/test/pg6762.txt: False\n",
      "(1, 24856)\n",
      "c : a\n",
      "data/aristotle/test/pg1974.txt: False\n"
     ]
    }
   ],
   "source": [
    "for f, cls_predict in files_test:\n",
    "    # load the test dataset\n",
    "    x_test = vectorizer.transform([open(f,'r', encoding='utf-8')])\n",
    "    # should be class C!\n",
    "    print(x_test.shape)\n",
    "    pred = getPredictValue(x_test,clf)\n",
    "    print(cls_predict,\":\",pred[0])\n",
    "    print (f\"{f}: {cls_predict == pred}\")\n",
    "    pass # remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## &#167;  You have now built your first document classifier! \n",
    "## Now answer the following questions:\n",
    "\n",
    "#### 1. How many of the documents did your classifier correctly classify?\n",
    "### Ans:\n",
    "The Four documents had classifier correctly classified. We can show results based on the above code results.The process of classifying or grouping documents into predefined set of classes based on a set of criteria that defined in advance is called text classification. TC has been exploited in various applications such as: documents organization, automated documents indexing, filtering of spams, text filtering, word sense disambiguation. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#167;  The classifier `predict` method only returns the label, but you can get the probabilities assigned to all\n",
    "classes using [`predict_proba()`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.predict_proba).\n",
    "Please take a look at the example notebook to see how that is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes Labels:  ['a' 'b' 'c']\n",
      "data/plato/test/pg1726.txt : [[0.33333333 0.33333333 0.33333333]]\n",
      "data/plato/test/pg1616.txt : [[0.33333333 0.33333333 0.33333333]]\n",
      "data/plato/test/pg1735.txt : [[0.33333333 0.33333333 0.33333333]]\n",
      "data/plato/test/pg1635.txt : [[0.33333333 0.33333333 0.33333333]]\n",
      "data/hume/test/pg59792-0.txt : [[0.33333333 0.33333333 0.33333333]]\n",
      "data/hume/test/pg62856-0.txt : [[0.33333333 0.33333333 0.33333333]]\n",
      "data/hume/test/pg9662.txt : [[0.33333333 0.33333333 0.33333333]]\n",
      "data/aristotle/test/pg59058.txt : [[0.33333333 0.33333333 0.33333333]]\n",
      "data/aristotle/test/pg2412.txt : [[0.33333333 0.33333333 0.33333333]]\n",
      "data/aristotle/test/pg6762.txt : [[0.33333333 0.33333333 0.33333333]]\n",
      "data/aristotle/test/pg1974.txt : [[0.33333333 0.33333333 0.33333333]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classes Labels: \",clf.classes_)\n",
    "for f, cls_predict in files_test:\n",
    "    # load the test dataset\n",
    "    x_test = vectorizer.transform([open(f,'r', encoding='utf-8')])\n",
    "    pred_proba = clf.predict_proba(x_test)\n",
    "    print(f,\":\",pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Answer the following questions inside your notebook:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Make an observation about the class probabilities.  What did you notice?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ans:\n",
    "#### An observation or input to the model is referred to as X and the class label or output of the model is referred to as y.\n",
    "#### Together, X and y represent observations collected from the domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please note that P(y) is also called class probability and P(xi | y) is called conditional probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the theorem, P(A) represents the probabilities of each event. In the Naive Bayes Classifier, we can interpret these Class Probabilities as simply the frequency of each instance of the event divided by the total number of instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A document d\n",
    "##### A fixed set of classes C = { c1, c2, … , cn }\n",
    "##### A training set of m documents that we have pre-determined to belong to a specific class\n",
    "#### We train our classifier using the training set, and result in a learned classifier.\n",
    "#### We can then use this learned classifier to classify new documents.\n",
    "#### Notation: we use Υ(d) = C to represent our classifier, where Υ() is the classifier, d is the document, and c is the class we assigned to the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Provide some commentary on how the probabilities might be improved (you can provide you answer as a thought exercise or if you have time, provide some example code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ans:\n",
    "By using the predict_prob() method to imporved the probabilities of Return probability estimates for the test vector X.\n",
    "The predict() function enables us to predict the labels of the data values on the basis of the trained model.\n",
    "It returns the labels of the data passed as argument based upon the learned or trained data obtained from the model.\n",
    "\n",
    "<br>The predict_proba(X) method return probability estimates for the test vector X.<br>\n",
    "As shown bellow example for <b>predict()</b> and <b>predict_prob()</b> results as follow.\n",
    "### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class:  [0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 2 0 0 1 2 2 0 2 1 0 0 1 2 1 2 1 2 2 0 1\n",
      " 0 1 2 2 0 2 2 1 2 0 0 0 2 0 0 2 2 2 2 2 1 2 1]\n",
      "60\n",
      "MultinomialNB Bayesian text classification model accuracy(in %): 93.33333333333333\n"
     ]
    }
   ],
   "source": [
    "# load the iris dataset \n",
    "from sklearn.datasets import load_iris \n",
    "iris = load_iris() \n",
    "  \n",
    "# store the feature matrix (X) and response vector (y) \n",
    "X = iris.data \n",
    "y = iris.target \n",
    "  \n",
    "# splitting X and y into training and testing sets \n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1) \n",
    "  \n",
    "# training the model on training set \n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "mnb = MultinomialNB() \n",
    "mnb.fit(X_train, y_train) \n",
    "\n",
    "# making predictions on the testing set \n",
    "y_pred = mnb.predict(X_test) \n",
    "print('Predicted Class: ',y_pred)\n",
    "print(len(y_pred))\n",
    "\n",
    "# comparing actual response values (y_test) with predicted response values (y_pred) \n",
    "from sklearn import metrics \n",
    "print(\"MultinomialNB Bayesian text classification model accuracy(in %):\", metrics.accuracy_score(y_test, y_pred)*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes Labels:  [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classes Labels: \",mnb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:  [0 1 2]\n",
      "Predicted Probabilities: \n",
      "[[0.84782459 0.10087277 0.05130264]\n",
      " [0.13897718 0.45635525 0.40466757]\n",
      " [0.065804   0.49378465 0.44041136]\n",
      " [0.77565499 0.14319566 0.08114934]\n",
      " [0.01479228 0.48808597 0.49712175]\n",
      " [0.04597056 0.4836567  0.47037274]\n",
      " [0.01343944 0.45799804 0.52856252]\n",
      " [0.66688299 0.20602622 0.12709079]\n",
      " [0.67993551 0.19761207 0.12245242]\n",
      " [0.0092437  0.44988817 0.54086813]\n",
      " [0.06001761 0.47836301 0.46161938]\n",
      " [0.72194203 0.17542687 0.1026311 ]\n",
      " [0.00979182 0.46035138 0.5298568 ]\n",
      " [0.05802771 0.48828932 0.45368297]\n",
      " [0.04535742 0.48033587 0.47430671]\n",
      " [0.71303904 0.17674608 0.11021487]\n",
      " [0.0769015  0.48261562 0.44048288]\n",
      " [0.04434897 0.47287291 0.48277812]\n",
      " [0.69120713 0.19348583 0.11530704]\n",
      " [0.74997422 0.1580045  0.09202128]\n",
      " [0.05535675 0.47924742 0.46539583]\n",
      " [0.04262238 0.46891271 0.4884649 ]\n",
      " [0.02974367 0.48440425 0.48585208]\n",
      " [0.74380682 0.16107334 0.09511984]\n",
      " [0.01583604 0.48099169 0.50317227]\n",
      " [0.06920573 0.47947769 0.45131658]\n",
      " [0.83669391 0.10706452 0.05624158]\n",
      " [0.75341297 0.15588276 0.09070427]\n",
      " [0.05661488 0.49044861 0.45293651]\n",
      " [0.01560128 0.46007061 0.52432811]\n",
      " [0.05213339 0.48534563 0.46252098]\n",
      " [0.00726961 0.45938214 0.53334825]\n",
      " [0.08518579 0.48000014 0.43481407]\n",
      " [0.00933963 0.44573683 0.54492354]\n",
      " [0.00777305 0.4219696  0.57025735]\n",
      " [0.7743441  0.14472812 0.08092778]\n",
      " [0.05399892 0.476305   0.46969608]\n",
      " [0.75222418 0.15761511 0.09016071]\n",
      " [0.04412842 0.48942642 0.46644516]\n",
      " [0.0109453  0.463015   0.5260397 ]\n",
      " [0.01227721 0.45960354 0.52811925]\n",
      " [0.73372126 0.16754483 0.0987339 ]\n",
      " [0.02134589 0.4709074  0.50774671]\n",
      " [0.01471222 0.46203543 0.52325235]\n",
      " [0.06190376 0.49672496 0.44137127]\n",
      " [0.0032063  0.43875495 0.55803876]\n",
      " [0.74829331 0.16170478 0.09000191]\n",
      " [0.7664619  0.14821399 0.08532412]\n",
      " [0.66000765 0.20876249 0.13122986]\n",
      " [0.059795   0.46838882 0.47181618]\n",
      " [0.7348892  0.16753374 0.09757707]\n",
      " [0.78551104 0.13866183 0.07582713]\n",
      " [0.00867533 0.46707934 0.52424534]\n",
      " [0.01428294 0.46478155 0.5209355 ]\n",
      " [0.01093249 0.47487673 0.51419078]\n",
      " [0.00812278 0.43977369 0.55210353]\n",
      " [0.02408976 0.46901186 0.50689838]\n",
      " [0.05264372 0.4785256  0.46883069]\n",
      " [0.0063535  0.46429468 0.52935182]\n",
      " [0.08208005 0.48025993 0.43766003]]\n"
     ]
    }
   ],
   "source": [
    "# Returns the probability of the samples for each class in the model. The columns correspond to the classes in sorted order, \n",
    "# as they appear in the attribute classes_.\n",
    "# predict(X): Perform classification on an array of test vectors X.\n",
    "# predict_proba(X) : Return probability estimates for the test vector X.\n",
    "y_pred_prob = mnb.predict_proba(X_test)\n",
    "print('Classes: ',mnb.classes_)\n",
    "print('Predicted Probabilities: ')\n",
    "print(y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The difference between predict() and predict_proba() is that predict will give you output like 0,1 and 2. \n",
    "#### Whereas predict_proba will give you the probability value of y being 0 or 1.\n",
    "#### predict() is used to predict the actual class (In your case one of 0, 1 or 1).\n",
    "#### predict_proba() is used to predict the class probabilities\n",
    "#### predict_proba() can let you use threshold a boundary probability value and used ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
